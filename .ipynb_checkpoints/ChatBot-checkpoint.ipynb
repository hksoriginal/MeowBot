{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8730eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5dcc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hksor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hksor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a758f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('bot.txt','r',errors = 'ignore') \n",
    "raw_doc =  f.read()\n",
    "raw_doc = raw_doc.lower()\n",
    "sent_tokens = nltk.sent_tokenize(raw_doc)\n",
    "word_tokens = nltk.word_tokenize(raw_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac25c30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python is a high-level, interpreted, general-purpose programming language being a general-purpose language, it can be used to build almost any type of application with the right tools/libraries additionally, python supports objects, modules, threads, exception-handling, and automatic memory management which help in modelling real-world problems and building applications to solve these problems.',\n",
       " 'python is an interpreted language, executes each statement line by line and thus type-checking is done on the fly, during execution hence, python is a dynamically typed language.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9bcf908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'is']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f654e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmmer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf25725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemTokens(tokens):\n",
    "    return [lemmmer.lemmatize(token) for token in tokens]\n",
    "remove_punc_dict = dict((ord(punc),None) for punc in string.punctuation)\n",
    "def lemNormalize(text):\n",
    "    return lemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15e3f5",
   "metadata": {},
   "source": [
    "# Defining Greeting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c923403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUTS = ('hello','hi','greetings','sup',\"what's up\",\"hey\")\n",
    "GREET_RESPONSES  = ['hiüòÅ','heyüòâ','*nods*','hi thereüòä','helloüòÑ','I am glad! You are talking to meü§ó','Jai Shree Ramüî•üî•']\n",
    "\n",
    "def greet(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word == 'jai': return 'Jai Shree Ramüî•üî•'\n",
    "        if word == 'ram': return 'Ram Ram üôè'\n",
    "        if word.lower() in GREET_INPUTS:\n",
    "            return random.choice(GREET_RESPONSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f3775",
   "metadata": {},
   "source": [
    "# Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "802c6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd8bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    bot_response = ''\n",
    "    tf_vec = TfidfVectorizer(tokenizer=lemNormalize,stop_words='english')\n",
    "    tf_vec_transformed = tf_vec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tf_vec_transformed[-1],tf_vec_transformed)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat =  vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if (req_tfidf == 0):\n",
    "        bot_response = bot_response + \"I'm sorry! I  don't understand that. Try again\"\n",
    "        return bot_response\n",
    "    else:\n",
    "        bot_response = bot_response + sent_tokens[idx]\n",
    "        return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72018818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mathematical functions\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9854d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mode(nums):return list(mode(nums))[0][0]\n",
    "def cal_median(nums):return np.median(nums)\n",
    "def cal_mean(nums): return np.mean(nums)\n",
    "def cal_sum(nums): return sum(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a8af3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "689.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_sum([34,56,34.6,565])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf54e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEOW: My name in Meowüò∫üò∫üò∫üò∫. let's have a  conversation around Data Science! Also, if you want to exit any time, just type Bye! \n",
      "USERüôä: what is python and median\n",
      "MEOWüò∫: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hksor\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:401: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  % sorted(inconsistent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python is an interpreted language, executes each statement line by line and thus type-checking is done on the fly, during execution hence, python is a dynamically typed language.\n",
      "Also, median is the middle number in a sorted, ascending or descending list of numbers and can be more descriptive of that data set than the average it is the point above and below which half (50%) the observed data falls, and so represents the midpoint of the data.USERüôä: what is deep learning and optimizers\n",
      "MEOWüò∫: deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network in the mid-1960s, alexey grigorevich ivakhnenko published the first general, while working on deep learning network deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.\n",
      "Also, I'm sorry! I  don't understand that. Try againUSERüôä: what is deep learning and gradient decent\n",
      "MEOWüò∫: deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network in the mid-1960s, alexey grigorevich ivakhnenko published the first general, while working on deep learning network deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.\n",
      "Also, mini batch gradient descent is considered to be the cross-over between gd and sgd in this approach instead of iterating through the entire dataset or one observation, we split the dataset into small subsets (batches) and compute the gradients for each batch is a hyperparameter that denotes the size of a single batch.USERüôä: what is classification\n",
      "MEOWüò∫: naive bayes algorithm is a supervised learning algorithm, which is based on bayes theorem and used for solving classification problems it is mainly used in text classification that includes a high-dimensional training dataset na√£¬Øve bayes classifier is one of the simple and most effective classification algorithms which helps in building the fast machine learning models that can make quick predictions it is a probabilistic classifier, which means it predicts on the basis of the probability of an object.\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "print(\"MEOW: My name in Meowüò∫üò∫üò∫üò∫. let's have a  conversation around Data Science! Also, if you want to exit any time, just type Bye! \")\n",
    "\n",
    "while (flag == True):\n",
    "    user_response= input(\"USERüôä: \")\n",
    "    user_response = user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response == 'thank you'):\n",
    "            flag = False\n",
    "            print('MEOWüò∫: You are welcome.')\n",
    "        else:\n",
    "            if(greet(user_response)!=None):\n",
    "                print('MEOWüò∫: '+ greet(user_response))\n",
    "            else:\n",
    "                word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
    "                final_word = list(set(word_tokens))\n",
    "                user_tokens = user_response.split()\n",
    "                if 'and'  in user_tokens:\n",
    "                    and_idx = user_tokens.index('and')\n",
    "                    first_q = user_tokens[:and_idx]\n",
    "                    first_q_text = str(' '.join(first_q))\n",
    "                    second_q = user_tokens[and_idx+1:]\n",
    "                    second_q_text = str(' '.join(second_q))\n",
    "                    print(\"MEOWüò∫: \",end=\"\")\n",
    "                    sent_tokens.append(first_q_text)\n",
    "                    print(response(first_q_text))\n",
    "                    sent_tokens.remove(first_q_text)\n",
    "                    sent_tokens.append(second_q_text)\n",
    "                    print('Also, ',end=response(second_q_text))\n",
    "                    sent_tokens.remove(second_q_text)\n",
    "                    print()\n",
    "                elif 'calculate' in user_tokens:\n",
    "                    cal_idx = user_tokens.index('calculate')\n",
    "                    op = user_tokens[cal_idx+1]\n",
    "                    op_idx = user_tokens.index(op)\n",
    "                    nums = user_tokens[op_idx+2:]\n",
    "                    nums = [float(i) for i in nums]\n",
    "                    if op == 'mean' or 'average':  print(\"MEOWüò∫: Mean is \",end=str(cal_mean(nums))+'\\n')\n",
    "                    if op == 'mode':  print(\"MEOWüò∫: Mode is \",end=str(cal_mode(nums)+'\\n'))\n",
    "                    if op == 'median':  print(\"MEOWüò∫: Median is \",end=str(cal_median(nums)+'\\n')) \n",
    "                        \n",
    "                else:\n",
    "                    sent_tokens.append(user_response)\n",
    "                    print()\n",
    "                    print(\"MEOWüò∫: \",end=\"\")\n",
    "                    print(response(user_response))\n",
    "                    sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"MEOW: GoodBye, Takecare‚ù§Ô∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad8e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c6f105eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf8092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f018079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
